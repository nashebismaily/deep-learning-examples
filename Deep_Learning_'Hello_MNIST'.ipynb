{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z1BMmhrW4-VF"
   },
   "source": [
    "# A tutorial introduction into deep learning with Keras and Tensorflow.  We will use the MNIST dataset which is the 'Hello world' problem of deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sfjjxqk-4-VY"
   },
   "source": [
    "I always like to start my jupternotebooks with this code because it fits the display window to my screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "oq3zQaj94-Vf",
    "outputId": "0375de18-9654-4b22-89c1-f6e04c750bc0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JTIiJaMH4-We"
   },
   "source": [
    "### This tutrial was adapted from Deep Learning with Python Chapter 2 Chollet, F. (2017). Deep Learning with Python (1st ed.). Greenwich, CT, USA: Manning Publications Co."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L7J8caRE4-Wv"
   },
   "source": [
    "Start with some definitions.\n",
    "Numerical data in an array are called tensors.  https://en.wikipedia.org/wiki/Tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pYhqLSfB4-W5"
   },
   "source": [
    "Scalars are 0 dimensional tensors (a single digit). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "sq1dfmTjXx1r",
    "outputId": "ddf0f915-fadf-4d87-cb65-308a51296a37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of x is 12\n",
      "The dimension of this tensor is 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array(12)\n",
    "print('The value of x is', x)\n",
    "print('The dimension of this tensor is', x.ndim) # 0 dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yd6j127g4-Xg"
   },
   "source": [
    "A 1 dimensional tensor is also called a vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "_iWxjAcgYF2H",
    "outputId": "3d2447cf-76b2-4034-d6a1-dcd12ccf55ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of x is [12  1  2  3]\n",
      "The dimention of this tensor is 1\n"
     ]
    }
   ],
   "source": [
    "x = np.array([12, 1, 2, 3]) #create a vector\n",
    "print('The value of x is', x)\n",
    "print('The dimention of this tensor is', x.ndim) # 1 dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SZnkKqX74-YS"
   },
   "source": [
    "A 2 dimensional tensor is also called a matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "id": "kw6vcniRYMga",
    "outputId": "f4ee5bc7-965a-4d85-b493-c50238941adb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of x is [[12  1  2  3]\n",
      " [ 5  6  7  8]\n",
      " [10 11 12 12]]\n",
      "The dimension of this tensor is 2\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[12, 1, 2, 3],\n",
    "              [5, 6, 7, 8,],\n",
    "              [10, 11, 12, 12]])\n",
    "print('The value of x is', x) # Print the 3 x 4 matrix\n",
    "print('The dimension of this tensor is', x.ndim) # 2 dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JDXBkNgF4-ZH"
   },
   "source": [
    "We can create n dimensional tensors easily, although they become difficult to visualize.\n",
    "This 3D tensor is like a cube of data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "7unoEvdhYbYR",
    "outputId": "35ecfa50-0dd5-4794-d417-c55fb2708995"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of x is [[[12  1  2  3]\n",
      "  [ 5  6  7  8]\n",
      "  [10 11 12 12]]\n",
      "\n",
      " [[ 2  2  2  2]\n",
      "  [ 3  3  3  3]\n",
      "  [ 4  4  4  4]]\n",
      "\n",
      " [[ 5  5  5  5]\n",
      "  [ 6  6  6  6]\n",
      "  [ 7  7  7  7]]]\n",
      "The dimension of this tensor is 3\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[[12, 1, 2, 3],\n",
    "               [5, 6, 7, 8,],\n",
    "               [10, 11, 12, 12]],\n",
    "              [[2, 2, 2, 2,],\n",
    "               [3,3,3,3],\n",
    "               [4,4,4,4]],\n",
    "              [[5,5,5,5],\n",
    "               [6,6,6,6],\n",
    "               [7,7,7,7]]])\n",
    "print('The value of x is', x)\n",
    "print('The dimension of this tensor is', x.ndim) # 3 dimensional array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6QrNkyOM4-Z0"
   },
   "source": [
    "#### Reshaping tensors is important concept to understand.  We can reshape a tensor as long as it has the same number of coefficients as the initial tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 752
    },
    "id": "x5jul5ly4-Z6",
    "outputId": "32959098-e2c0-4060-f79e-f121b612ae36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12]\n",
      " [ 1]\n",
      " [ 2]\n",
      " [ 3]\n",
      " [ 5]\n",
      " [ 6]\n",
      " [ 7]\n",
      " [ 8]\n",
      " [10]\n",
      " [11]\n",
      " [12]\n",
      " [12]\n",
      " [ 2]\n",
      " [ 2]\n",
      " [ 2]\n",
      " [ 2]\n",
      " [ 3]\n",
      " [ 3]\n",
      " [ 3]\n",
      " [ 3]\n",
      " [ 4]\n",
      " [ 4]\n",
      " [ 4]\n",
      " [ 4]\n",
      " [ 5]\n",
      " [ 5]\n",
      " [ 5]\n",
      " [ 5]\n",
      " [ 6]\n",
      " [ 6]\n",
      " [ 6]\n",
      " [ 6]\n",
      " [ 7]\n",
      " [ 7]\n",
      " [ 7]\n",
      " [ 7]]\n",
      "[[12  1  2  3  5  6  7  8 10]\n",
      " [11 12 12  2  2  2  2  3  3]\n",
      " [ 3  3  4  4  4  4  5  5  5]\n",
      " [ 5  6  6  6  6  7  7  7  7]]\n"
     ]
    }
   ],
   "source": [
    "x = x.reshape(3*3*4,1)\n",
    "print(x)\n",
    "x = x.reshape(4, 3*3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ihVQabEo4-aS"
   },
   "source": [
    "##### Tensors have three atributes: number of axis (dimensions), shape (length of each axis), and data type (typically we will use float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CUA1N4pS4-aY"
   },
   "source": [
    "Load the MNIST library which is part of Keras.  MNIST stands for Modified National Institute of Technology. https://en.wikipedia.org/wiki/MNIST_database. It is a collection of 60,000 training and 10,000 test images of the digits 0-9. https://keras.io/datasets/. We will build a deep learning nerual net model to classify the 10 digits. This is the 'Hello World' problem of deep learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "1AG-iMB8P3DZ"
   },
   "outputs": [],
   "source": [
    "# From the tensorflow data sets import MNIST\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "5Efu6_zaQKtQ",
    "outputId": "b469ac37-38b7-43d0-8521-49819b011a79"
   },
   "outputs": [],
   "source": [
    "(train_images, train_labels),(test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "ZYu3aOo4Qn9R",
    "outputId": "769f97fb-a084-4a99-e885-cb0531b87883"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape #60,000 images that are 28 pixles by 28 pixles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "73Jt87YRZBXe",
    "outputId": "2a7cc881-8643-4066-ea63-61b49e3aa246"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.ndim #3D tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "q_fgMe2h4-bm",
    "outputId": "c3aeaf92-3a62-4673-b127-1b96415f3d0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum value in the array is 255\n",
      "he minimum value in the array is 0\n"
     ]
    }
   ],
   "source": [
    "print('The maximum value in the array is', train_images.max()) # The maximum value in the array is 255\n",
    "print('he minimum value in the array is', train_images.min()) # The minimum value in the array is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ACNHKDMhZMtH"
   },
   "outputs": [],
   "source": [
    "# Get the shape, dimensions, max and min value of the test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "id": "LvcS2anBQ8cd",
    "outputId": "820a862a-593c-4dcd-9d8a-a64b2aaf46ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test image shape: (10000, 28, 28)\n",
      "number of dimensions: 3\n",
      "maximum value 255\n",
      "minimum value: 0\n"
     ]
    }
   ],
   "source": [
    "print('test image shape:', test_images.shape)\n",
    "print('number of dimensions:', test_images.ndim)\n",
    "print('maximum value', test_images.max())\n",
    "print('minimum value:', test_images.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lAWThxtY4-co"
   },
   "source": [
    "In general the first axis in a tensor is the samples, the second axis is height, the third axis is the width, and the fourth is color channels (RGB = 3 & BW = 1)\n",
    "So image data will be a 4D tensor [samples, height, width, channels] the MNIST data is 3D bacause the color channel is black and white and thus = 1\n",
    "Video data will be a 5D tensor [samples, frames, height, width, channels]. By convention, time series data will be placed on the secod axis when present"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kavsqyWG4-cZ"
   },
   "source": [
    "Let's view one of the images.  We need to import matplotlib to view the digits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "jwEiakpiZXnf"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "HvYknn0hZf51",
    "outputId": "889f44ad-6b4c-416c-df49-7a12b477db00"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "digit = train_images[4] # Select the fouth sample.\n",
    "plt.imshow(digit, cmap=plt.cm.binary) # Show the sample.  cmap is the color map.  We will keep it black and white (binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "gSBcnrgsRPJ3"
   },
   "outputs": [],
   "source": [
    "# Import models and layers from tensorflow \n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "w8lxhcrHRV0x"
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(512, activation='relu',input_shape=(28 * 28,)))\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "TcixP8_xR5j7"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam',\n",
    "               loss = 'categorical_crossentropy',\n",
    "               metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "cEeckA5ESIMB",
    "outputId": "ee76ea3d-980e-4616-fd91-6ca038b01e6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "train_images =  train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32')/train_images.max()\n",
    "\n",
    "print(train_images.ndim)\n",
    "\n",
    "test_images =  test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32')/test_images.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "Crqw7E-x4-eh",
    "outputId": "14f50c1a-cd40-4b1a-f812-dbba438fd30b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f32a99cc3c8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_images.reshape((60000,28,28))[4], cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "id": "bw_1wSzI4-ex",
    "outputId": "b41f64f5-6d86-4970-f8a7-c7ba99201288"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train image shape: (60000, 784)\n",
      "number of dimensions: 2\n",
      "maximum value 1.0\n",
      "minimum value: 0.0\n"
     ]
    }
   ],
   "source": [
    "print('train image shape:', train_images.shape)\n",
    "print('number of dimensions:', train_images.ndim)\n",
    "print('maximum value', train_images.max())\n",
    "print('minimum value:', train_images.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "44PHpAPRUVyV"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "zeczsZHUVDQx"
   },
   "outputs": [],
   "source": [
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "id": "w90ZrgWhVPC1",
    "outputId": "b423318e-656b-4353-f686-abcca13fbfd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.2629 - accuracy: 0.9254\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1075 - accuracy: 0.9685\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.0692 - accuracy: 0.9797\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.0495 - accuracy: 0.9856\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.0359 - accuracy: 0.9895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f32a86a4f60>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs = 5, batch_size = 120) \n",
    "# Batch size is how many images to process at once. Epoch is how many times to repeat the analysis.  Each epoch performs 500 gradient updates (60,000/120 = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "OHqqd_YYVdz3",
    "outputId": "177ef72e-0444-460e-fa68-466aaa8158bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 885us/step - loss: 0.0638 - accuracy: 0.9797\n",
      "test_acc: 0.9797000288963318\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sIRCQyZ2F24o"
   },
   "source": [
    "# Your Turn\n",
    "####  Build 3 different models with activations 'relu', 'tanh', and 'sigmoid'.  The last activation must be 'softmax' since we have a multiclass problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "KgHnMI6T4-f6"
   },
   "outputs": [],
   "source": [
    "relu_model = models.Sequential()\n",
    "relu_model.add(layers.Dense(512, activation='relu',input_shape=(28 * 28,)))\n",
    "relu_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "tanh_model = models.Sequential()\n",
    "tanh_model.add(layers.Dense(512, activation='tanh',input_shape=(28 * 28,)))\n",
    "tanh_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "sigmoid_model = models.Sequential()\n",
    "sigmoid_model.add(layers.Dense(512, activation='sigmoid',input_shape=(28 * 28,)))\n",
    "sigmoid_model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BnUDSgXk4-gE"
   },
   "source": [
    "#### Compile your model.  Use categorical_crossentropyy since this problem is a multiclassification problem. Metrics will be 'accuracy' and optimizer will be 'adam'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "FhHGydeC4-gH"
   },
   "outputs": [],
   "source": [
    "relu_model.compile(optimizer = 'adam',\n",
    "               loss = 'categorical_crossentropy',\n",
    "               metrics = ['accuracy'])\n",
    "\n",
    "tanh_model.compile(optimizer = 'adam',\n",
    "               loss = 'categorical_crossentropy',\n",
    "               metrics = ['accuracy'])\n",
    "\n",
    "sigmoid_model.compile(optimizer = 'adam',\n",
    "               loss = 'categorical_crossentropy',\n",
    "               metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X7uSP2vm4-gR"
   },
   "source": [
    "#### Fit the models with epochs = 5 and  batch_size = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "Y9qFLRMA4-gT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2816 - accuracy: 0.9205\n",
      "Epoch 2/5\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.1153 - accuracy: 0.9664\n",
      "Epoch 3/5\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0760 - accuracy: 0.9776\n",
      "Epoch 4/5\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0538 - accuracy: 0.9844\n",
      "Epoch 5/5\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0408 - accuracy: 0.9879\n",
      "Epoch 1/5\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.3319 - accuracy: 0.9047\n",
      "Epoch 2/5\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.1874 - accuracy: 0.9456\n",
      "Epoch 3/5\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.1278 - accuracy: 0.9637\n",
      "Epoch 4/5\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0938 - accuracy: 0.9732\n",
      "Epoch 5/5\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0708 - accuracy: 0.9793\n",
      "Epoch 1/5\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.4638 - accuracy: 0.8779\n",
      "Epoch 2/5\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2533 - accuracy: 0.9273\n",
      "Epoch 3/5\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2001 - accuracy: 0.9429\n",
      "Epoch 4/5\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.1624 - accuracy: 0.9528\n",
      "Epoch 5/5\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.1343 - accuracy: 0.9612\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f32a435d7f0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu_model.fit(train_images, train_labels, epochs = 5, batch_size = 150) \n",
    "tanh_model.fit(train_images, train_labels, epochs = 5, batch_size = 150) \n",
    "sigmoid_model.fit(train_images, train_labels, epochs = 5, batch_size = 150) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WB4RPCz54-gb"
   },
   "source": [
    "#### Test the accuracy of the model on the test images and test labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "W7V6DjwV4-gc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 880us/step - loss: 0.0692 - accuracy: 0.9782\n",
      "relu_test_acc: 0.9782000184059143\n",
      "313/313 [==============================] - 0s 919us/step - loss: 0.0914 - accuracy: 0.9730\n",
      "tanh_test_acc: 0.9729999899864197\n",
      "313/313 [==============================] - 0s 913us/step - loss: 0.1319 - accuracy: 0.9602\n",
      "sigmoid_model_test_acc: 0.9602000117301941\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = relu_model.evaluate(test_images, test_labels)\n",
    "print('relu_test_acc:', test_acc)\n",
    "\n",
    "test_loss, test_acc = tanh_model.evaluate(test_images, test_labels)\n",
    "print('tanh_test_acc:', test_acc)\n",
    "\n",
    "test_loss, test_acc = sigmoid_model.evaluate(test_images, test_labels)\n",
    "print('sigmoid_model_test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DbR0ds5G4-gm"
   },
   "source": [
    "#### which activation gave the highest accuracy?\n",
    "\n",
    "The RELU activation gave the highest accuracy of 0.9782\n",
    "\n",
    "### Using the acitvation that gave the highest accuracy build 3 different models with 3 hidden layers and varying units in each hidden layer.  The first and output layers are given to you.  Use the same 'relu' activation fuction on the input and hidden layers throughout so you can compare how adding nodes and hidden layers effect your model performance with the same activation function.\n",
    "### By convention hidden layers are built in orders of 2^x.  For example: 2, 4, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096, etc. Built three models where the nodes (units) grow, stay consistant, and decrease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "BTh369rD4-gr"
   },
   "outputs": [],
   "source": [
    "# First model have the nodes increase from 2\n",
    "h1_model = models.Sequential()\n",
    "h1_model.add(layers.Dense(2, activation='relu',input_shape=(28 * 28,)))\n",
    "h1_model.add(layers.Dense(32, activation='relu',input_shape=(28 * 28,)))\n",
    "h1_model.add(layers.Dense(256, activation='relu',input_shape=(28 * 28,)))\n",
    "h1_model.add(layers.Dense(2048, activation='relu',input_shape=(28 * 28,)))\n",
    "h1_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Second model have the nodes stay consistant at 512\n",
    "h2_model = models.Sequential()\n",
    "h2_model.add(layers.Dense(512, activation='relu',input_shape=(28 * 28,)))\n",
    "h2_model.add(layers.Dense(512, activation='relu',input_shape=(28 * 28,)))\n",
    "h2_model.add(layers.Dense(512, activation='relu',input_shape=(28 * 28,)))\n",
    "h2_model.add(layers.Dense(512, activation='relu',input_shape=(28 * 28,)))\n",
    "h2_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Third model, have the nodes decrease from 2048\n",
    "h3_model = models.Sequential()\n",
    "h3_model.add(layers.Dense(2048, activation='relu',input_shape=(28 * 28,)))\n",
    "h3_model.add(layers.Dense(256, activation='relu',input_shape=(28 * 28,)))\n",
    "h3_model.add(layers.Dense(32, activation='relu',input_shape=(28 * 28,)))\n",
    "h3_model.add(layers.Dense(2, activation='relu',input_shape=(28 * 28,)))\n",
    "h3_model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EY-vLrzS4-g1"
   },
   "source": [
    "#### Complie the three models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "AvYLN-Ld4-g3"
   },
   "outputs": [],
   "source": [
    "h1_model.compile(optimizer = 'adam',\n",
    "               loss = 'categorical_crossentropy',\n",
    "               metrics = ['accuracy'])\n",
    "\n",
    "h2_model.compile(optimizer = 'adam',\n",
    "               loss = 'categorical_crossentropy',\n",
    "               metrics = ['accuracy'])\n",
    "\n",
    "h3_model.compile(optimizer = 'adam',\n",
    "               loss = 'categorical_crossentropy',\n",
    "               metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jRMZ56yI4-hF"
   },
   "source": [
    "#### Fit the models with epochs = 5 and  batch_size = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "wO_mcJ9x4-hI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "400/400 [==============================] - 1s 4ms/step - loss: 1.2272 - accuracy: 0.5365\n",
      "Epoch 2/5\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.9590 - accuracy: 0.6636\n",
      "Epoch 3/5\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.9003 - accuracy: 0.6875\n",
      "Epoch 4/5\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.8688 - accuracy: 0.7035\n",
      "Epoch 5/5\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.8438 - accuracy: 0.7141\n",
      "Epoch 1/5\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.2252 - accuracy: 0.9312\n",
      "Epoch 2/5\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0899 - accuracy: 0.9722\n",
      "Epoch 3/5\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0600 - accuracy: 0.9813\n",
      "Epoch 4/5\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0448 - accuracy: 0.9857\n",
      "Epoch 5/5\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0393 - accuracy: 0.9877\n",
      "Epoch 1/5\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 1.9242 - accuracy: 0.2040\n",
      "Epoch 2/5\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 1.7941 - accuracy: 0.2213\n",
      "Epoch 3/5\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 1.7348 - accuracy: 0.2846\n",
      "Epoch 4/5\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 1.7036 - accuracy: 0.3020\n",
      "Epoch 5/5\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 1.6730 - accuracy: 0.3129\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f32a4077828>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1_model.fit(train_images, train_labels, epochs = 5, batch_size = 150) \n",
    "h2_model.fit(train_images, train_labels, epochs = 5, batch_size = 150) \n",
    "h3_model.fit(train_images, train_labels, epochs = 5, batch_size = 150) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x0Kcmj6x4-hU"
   },
   "source": [
    "#### Test the accuracy of the 3 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "uRUw9R5F4-ha"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.8241 - accuracy: 0.7285\n",
      "h1_model_test_acc: 0.7285000085830688\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0949 - accuracy: 0.9727\n",
      "h2_model_test_acc: 0.9726999998092651\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 1.7265 - accuracy: 0.2817\n",
      "h3_model_model_model_test_acc: 0.2816999852657318\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = h1_model.evaluate(test_images, test_labels)\n",
    "print('h1_model_test_acc:', test_acc)\n",
    "\n",
    "test_loss, test_acc = h2_model.evaluate(test_images, test_labels)\n",
    "print('h2_model_test_acc:', test_acc)\n",
    "\n",
    "test_loss, test_acc = h3_model.evaluate(test_images, test_labels)\n",
    "print('h3_model_model_model_test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2-fHqdpQ4-hm"
   },
   "source": [
    "#### Which model gave the highest accuracy?\n",
    "\n",
    "The Second model which had the nodes stay consistent at 512 gave the greatest accuracy of 0.9727"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [
    "2-fHqdpQ4-hm"
   ],
   "name": "Deep_Learning_'Hello_MNIST'.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
